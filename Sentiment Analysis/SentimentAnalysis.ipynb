{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "errors=0\n",
    "\n",
    "# data initialization\n",
    "\n",
    "def read_files(sentiment_dictionary, sentences_train, sentences_test):\n",
    "  pos_sent=open('rt-polarity.pos', 'r', encoding='ISO-8859-1')\n",
    "  pos_sent=re.split(r'\\n', pos_sent.read())\n",
    "\n",
    "  neg_sent=open('rt-polarity.neg', 'r', encoding='ISO-8859-1')\n",
    "  neg_sent=re.split(r'\\n', neg_sent.read())\n",
    "\n",
    "  pos_dictionary = open('positive-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "  pos_wordlist = pos_dictionary.readlines()\n",
    "  pos_wordlist = [line.strip() for line in pos_wordlist if not line.startswith(\";\") and not line == '\\n']\n",
    " \n",
    "  neg_dictionary = open('negative-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "  neg_wordlist = neg_dictionary.readlines()\n",
    "  neg_wordlist = [line.strip() for line in neg_wordlist if not line.startswith(\";\") and not line == '\\n']\n",
    "\n",
    "  for i in pos_wordlist:\n",
    "        sentiment_dictionary[i] = 1\n",
    "  for i in neg_wordlist:\n",
    "        sentiment_dictionary[i] = -1\n",
    "\n",
    "  for i in pos_sent:\n",
    "        if random.randint(1,10)<2:\n",
    "            sentences_test[i]=\"positive\"\n",
    "        else:\n",
    "            sentences_train[i]=\"positive\"\n",
    "\n",
    "  for i in neg_sent:\n",
    "        if random.randint(1,10)<2:\n",
    "            sentences_test[i]=\"negative\"\n",
    "        else:\n",
    "            sentences_train[i]=\"negative\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def testBayes(sentences_test, dataName, pWordPos, pWordNeg, pWord,pPos):\n",
    "    pNeg=1-pPos\n",
    "\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalpospred=0\n",
    "    totalneg=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "\n",
    "    for sentence, sentiment in sentences_test.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
    "\n",
    "        bigramList=wordList.copy() #initialise bigramList\n",
    "        for x in range(len(wordList)-1):\n",
    "           bigramList.append(wordList[x]+\"_\" + wordList[x+1])\n",
    "\n",
    "        trigramList=bigramList     #initialise trigtamList\n",
    "        for x in range(len(wordList)-2):\n",
    "            trigramList.append(wordList[x]+\"_\"+wordList[x+1]+\"_\"+wordList[x+2])\n",
    "        \n",
    "        \n",
    "        pPosW=pPos\n",
    "        pNegW=pNeg\n",
    "\n",
    "\n",
    "        for word in bigramList: #calculate over bigrams\n",
    "            if word in pWord:\n",
    "                if pWord[word]>0.00000001:\n",
    "                    pPosW *=pWordPos[word]\n",
    "                    pNegW *=pWordNeg[word]\n",
    "\n",
    "        prob=0;            \n",
    "        if pPosW+pNegW >0:\n",
    "            prob=pPosW/float(pPosW+pNegW)\n",
    "\n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if prob>0.5:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "                if errors:\n",
    "                    print (\"ERROR (pos classed as neg %0.2f):\" %prob + sentence)\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if prob<=0.5:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    "                if errors:\n",
    "                    print (\"ERROR (neg classed as pos %0.2f):\" %prob + sentence)\n",
    "    acc=correct/float(total)\n",
    "    print (dataName + \" Accuracy (All)=%0.2f\" % acc + \" (%d\" % correct + \"/%d\" % total + \")\")\n",
    "\n",
    "    precision_pos=correctpos/float(totalpospred)\n",
    "    recall_pos=correctpos/float(totalpos)\n",
    "    precision_neg=correctneg/float(totalnegpred)\n",
    "    recall_neg=correctneg/float(totalneg)\n",
    "    f_pos=2*precision_pos*recall_pos/(precision_pos+recall_pos);\n",
    "    f_neg=2*precision_neg*recall_neg/(precision_neg+recall_neg);\n",
    "\n",
    "    print (dataName + \" Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print (dataName + \" Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print (dataName + \" F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print (dataName + \" Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print (dataName + \" Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print (dataName + \" F-measure (Neg)=%0.2f\" % f_neg)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dictionary(sentences_test, dataName, sentiment_dictionary, threshold):\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "    for sentence, sentiment in sentences_test.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence)\n",
    "        score=0\n",
    "        for word in Words:\n",
    "            if word in sentiment_dictionary:\n",
    "               score+=sentiment_dictionary[word]\n",
    " \n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if score<threshold:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    " \n",
    "    acc=correct/float(total)\n",
    "    print (dataName + \" Accuracy (All)=%0.2f\" % acc + \"(%d\" % correct + \"/%d\" % total +\")\")\n",
    "    precision_pos=correctpos/float(totalpospred)\n",
    "    recall_pos=correctpos/float(totalpos)\n",
    "    precision_neg=correctneg/float(totalnegpred)\n",
    "    recall_neg=correctneg/float(totalneg)\n",
    "    f_pos=2*precision_pos*recall_pos/(precision_pos+recall_pos);\n",
    "    f_neg=2*precision_neg*recall_neg/(precision_neg+recall_neg);\n",
    "\n",
    "\n",
    "    print (dataName + \" Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print (dataName + \" Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print (dataName + \" F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print (dataName + \" Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print (dataName + \" Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print (dataName + \" F-measure (Neg)=%0.2f\" % f_neg )\n",
    "\n",
    "def mostUseful(pWordPos, pWordNeg, pWord, n):\n",
    "    predictPower={}\n",
    "    for word in pWord:\n",
    "        if pWordNeg[word]<0.0000001:\n",
    "            predictPower[word]=1000000000\n",
    "        else:\n",
    "            predictPower[word]=pWordPos[word] / (pWordPos[word] + pWordNeg[word])\n",
    "\n",
    "    sortedPower = sorted(predictPower, key=predictPower.get)\n",
    "    head, tail = sortedPower[:n], sortedPower[len(predictPower)-n:]\n",
    "    print (\"\\nNEGATIVE:\")\n",
    "    print (head)\n",
    "    print (\"\\nPOSITIVE:\")\n",
    "    print (tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['enigma', 'is', 'well', 'made', 'but', \"it's\", 'just', 'too', 'dry', 'and', 'too', 'placid', 'enigma_is', 'is_well', 'well_made', 'made_but', \"but_it's\", \"it's_just\", 'just_too', 'too_dry', 'dry_and', 'and_too', 'too_placid', 'enigma_is_well', 'is_well_made', 'well_made_but', \"made_but_it's\", \"but_it's_just\", \"it's_just_too\", 'just_too_dry', 'too_dry_and', 'dry_and_too', 'and_too_placid']\n",
      "\n",
      "Naive Bayes\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.82 (7844/9595)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.93 (3300/3564)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.69 (3300/4787)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.79\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.75 (4544/6031)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.95 (4544/4808)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.84\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.80 (851/1068)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.80 (436/545)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.80 (436/544)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.80\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.79 (415/523)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.79 (415/524)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.79\n",
      "NEGATIVE:\n",
      "['generic', 'badly', 'waste', 'mediocre', 'unfunny', 'routine', 'the_problem', 'ends_up', 'poorly', 'supposed_to', 'mindless', 'stale', 'boring', 'feels_like_a', 'shoot', 'of_the_characters', '90_minutes', 'pointless', \"wasn't\", 'nowhere', 'unless', 'waste_of', 'not_enough', 'sit_through', 'only_thing', 'the_only_thing', 'far_too', 'stupid', 'mess', 'disaster', 'wants_to_be', 'meandering', 'should_have_been', 'never_really', 'bore', 'disguise', 'annoying', 'flat', 'a_script', 'inept', 'it_were', 'apparently', 'save', 'offensive', 'tiresome', 'plodding', 'lousy', 'feature_length', 'lifeless', 'pinocchio']\n",
      "\n",
      "POSITIVE:\n",
      "['a_thoughtful', 'playful', 'iranian', 'resonant', 'but_still', 'tour', 'captivating', 'spare', 'grown', 'best_films', 'respect', 'a_look', 'makes_up', 'makes_up_for', 'heartwarming', 'charming_and', 'captures', 'tender', 'a_terrific', 'polished', 'strength', 'wry', 'is_at', 'a_sweet', 'study_of', 'gem', 'lively', 'vividly', 'chilling', 'portrait_of_a', 'extraordinary', 'powerful', 'an_engaging', 'a_smart', 'mesmerizing', 'wonderful', 'wonderfully', 'love_and', 'a_powerful', 'vivid', 'in_years', 'refreshingly', 'refreshing', 'realistic', 'performances_from', 'riveting', 'inventive', 'what_makes', 'engrossing', 'of_the_best']\n"
     ]
    }
   ],
   "source": [
    "sentiment_dictionary={} # {} initialises a dictionary [hash function]\n",
    "sentences_train={}\n",
    "sentences_test={}\n",
    "\n",
    "#initialise datasets and dictionaries\n",
    "read_files(sentiment_dictionary,sentences_train,sentences_test) \n",
    "\n",
    "pWordPos={} # p(W|Positive)\n",
    "pWordNeg={} # p(W|Negative)\n",
    "pWord={}    # p(W) \n",
    "\n",
    "#build conditional probabilities using training data\n",
    "trainBayes(sentences_train, pWordPos, pWordNeg, pWord)\n",
    "\n",
    "#run naive bayes classifier on datasets\n",
    "print (\"\\nNaive Bayes\")\n",
    "testBayes(sentences_train,  \"\\nFilms (Train Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "testBayes(sentences_test,  \"\\nFilms  (Test Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "\n",
    "# print most useful words\n",
    "mostUseful(pWordPos, pWordNeg, pWord, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
